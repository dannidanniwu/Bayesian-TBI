scenarios <- expand.grid(n = c(500, 1000, 2000),
p = 5,
g.choice=c("linear", "nonlinear"),
m.choice=c("linear"))
scenarios
generate.data2 <- function(n = 200, p = 10, #family = "gaussian",
correlationX = 0.2,
sigmaX = 1, #sigma = 0.4, s = 2, delta = 1,
g.choice = "nonlinear", # "linear"
m.choice = "linear",  # "nonlinear"
pi.1 = 0.5)
{
true.beta <- c(c(1, 0.5, 0.25, 0.125), rep(0, p - 4))
true.beta <- true.beta/sqrt(sum(true.beta^2))#sum(true.beta^2)=1
eta.hold <- c(1, 2, 3, 4)
eta.hold <- eta.hold/sqrt(sum(eta.hold^2))
true.eta <- c(rep(0, p - 4), eta.hold)
if(g.choice=="nonlinear"){
g <- function(u) exp(-(u - 0.5)^2) - 0.6
}else{
g <- function(u) 0.3 * u
}
if(m.choice=="nonlinear"){
m <- function(u) 0.5* sin(u * 0.5 * pi)
}else{ # "linear"
m <- function(u) 0.125* u * pi
}
A <- drop(rbinom(n, 1, pi.1) + 1)#A:treatment assignment: 1 or 2
Psix <- sigmaX * (diag(1 - correlationX, nrow = p, ncol = p) +
matrix(correlationX, nrow = p, ncol = p))#covariance matrix
ePsix <- eigen(Psix)
X <- sapply(1:p, function(x) rnorm(n)) %*% diag(sqrt(ePsix$values)) %*% t(ePsix$vectors)
main.effect <- m(drop(X %*% true.eta))
g.effect <- g(drop(X %*% true.beta))
interaction.effect <- 2 * (as.numeric(A) + pi.1 - 2) * g.effect
# potential expected outcome
mu.1 <- 1/(1 + exp(-(main.effect+  2 * (pi.1 - 1) *g.effect)))#A=1;trt=-0.5
mu.2 <- 1/(1 + exp(-(main.effect+  2 * pi.1 *g.effect)))#A=2;trt=0.5
# canonical parameter
theta <- main.effect + interaction.effect
SNR <- var(interaction.effect)/var(main.effect)
SNR
mu <- 1/(1 + exp(-theta))#P(Y=1|theta)
y <- rbinom(n, size = 1, prob = mu)
optTr <- ifelse(mu.2 > mu.1, 1, 2)  # smaller outcome desirable
value.opt <- mean((optTr==1)*mu.1 + (optTr==2)*mu.2)
value.opt ##E(P(Y=1|theta)) using optimal trt
list(y = y, A = A, X = X, SNR = SNR, true.beta = true.beta,
true.eta = true.eta, m.choice=m.choice, #delta = delta, s = s,
mu.1 = mu.1, mu.2 = mu.2, optTr = optTr, value.opt = value.opt)
}
library(splines)
library(movMF)
library(mgcv)
library(simml)
library(cmdstanr)
library(posterior)
library(data.table)
library(dplyr)
library(slurmR)
library(stableGR)
# generate training data
data <- generate.data2(n=n, p=p, correlationX=correlationX, sigmaX=sigmaX, g.choice=g.choice,m.choice=m.choice, pi.1=pi.1)
n = 500,
p = 10
g.choice = "linear"
m.choice = "linear"
correlationX = 0.2
sigmaX = 1
pi.1 = 0.5
beta.ini = c(1,rep(0,p-1))
# generate training data
data <- generate.data2(n=n, p=p, correlationX=correlationX, sigmaX=sigmaX, g.choice=g.choice,m.choice=m.choice, pi.1=pi.1)
pi.1 = 0.5
# generate training data
data <- generate.data2(n=n, p=p, correlationX=correlationX, sigmaX=sigmaX, g.choice=g.choice,m.choice=m.choice, pi.1=pi.1)
pi.1
c
# generate training data
data <- generate.data2(n=n, p=p, correlationX=correlationX, sigmaX=sigmaX, g.choice=g.choice,m.choice=m.choice, pi.1=pi.1)
rbinom(n, 1, 0.5)
n
n = 500
# generate training data
data <- generate.data2(n=n, p=p, correlationX=correlationX, sigmaX=sigmaX, g.choice=g.choice,m.choice=m.choice, pi.1=pi.1)
data$X
head(data$X)
head(data$A)
load("/Users/danni/Library/CloudStorage/OneDrive-NYULangoneHealth/Bayesian stepped wedge/Bayesian-stepped-wedge/Data/GAM_timespline_bayes_freq.rda")
View(results_agg)
load("/Users/danni/Library/CloudStorage/OneDrive-NYULangoneHealth/Bayesian stepped wedge/Bayesian-stepped-wedge/Data/GAM_bayes_freq.rda")
View(results_agg)
View(results_agg)
View(results_agg)
head(data)
summary(dd$x)
library(posterior)
library(data.table)
library(dplyr)
library(slurmR)
library(stableGR)  # to compute the Gelman-Rubin diagnostic statistic
###Generate data
generate.data2 <- function(n = 200, p = 10, #family = "gaussian",
correlationX = 0.2,
sigmaX = 1, #sigma = 0.4, s = 2, delta = 1,
g.choice = "nonlinear", # "linear"
m.choice = "linear",  # "nonlinear"
pi.1 = 0.5)
{
true.beta <- c(c(1, 0.5, 0.25, 0.125), rep(0, p - 4))
true.beta <- true.beta/sqrt(sum(true.beta^2))#sum(true.beta^2)=1
eta.hold <- c(1, 2, 3, 4)
eta.hold <- eta.hold/sqrt(sum(eta.hold^2))
true.eta <- c(rep(0, p - 4), eta.hold)
if(g.choice=="nonlinear"){
g <- function(u) exp(-(u - 0.5)^2) - 0.6
}else{
g <- function(u) 0.3 * u
}
if(m.choice=="nonlinear"){
m <- function(u) 0.5* sin(u * 0.5 * pi)
}else{ # "linear"
m <- function(u) 0.125* u * pi
}
A <- drop(rbinom(n, 1, pi.1) + 1)#A:treatment assignment: 1 or 2
Psix <- sigmaX * (diag(1 - correlationX, nrow = p, ncol = p) +
matrix(correlationX, nrow = p, ncol = p))#covariance matrix
ePsix <- eigen(Psix)
X <- sapply(1:p, function(x) rnorm(n)) %*% diag(sqrt(ePsix$values)) %*% t(ePsix$vectors)
main.effect <- m(drop(X %*% true.eta))
g.effect <- g(drop(X %*% true.beta))
interaction.effect <- 2 * (as.numeric(A) + pi.1 - 2) * g.effect
# potential expected outcome
mu.1 <- 1/(1 + exp(-(main.effect+  2 * (pi.1 - 1) *g.effect)))#A=1;trt=-0.5
mu.2 <- 1/(1 + exp(-(main.effect+  2 * pi.1 *g.effect)))#A=2;trt=0.5
# canonical parameter
theta <- main.effect + interaction.effect
SNR <- var(interaction.effect)/var(main.effect)
SNR
mu <- 1/(1 + exp(-theta))#P(Y=1|theta)
y <- rbinom(n, size = 1, prob = mu)
optTr <- ifelse(mu.2 > mu.1, 1, 2)  # smaller outcome desirable
value.opt <- mean((optTr==1)*mu.1 + (optTr==2)*mu.2)
value.opt ##E(P(Y=1|theta)) using optimal trt
list(y = y, A = A, X = X, SNR = SNR, true.beta = true.beta,
true.eta = true.eta, m.choice=m.choice, #delta = delta, s = s,
mu.1 = mu.1, mu.2 = mu.2, optTr = optTr, value.opt = value.opt)
}
library(splines)
library(movMF)
library(mgcv)
library(simml)
library(cmdstanr)
n = 500
p=5
g.choice = "linear"
m.choice = "linear"
correlationX = 0.2
sigmaX = 1
pi.1 = 0.5
beta.ini = c(1,rep(0,p-1))
n.test =10000
n.samples= 2000
n.burning= 2000
lambda.prior=100
lambda.proposal=1000
# generate training data
data <- generate.data2(n=n, p=p, correlationX=correlationX, sigmaX=sigmaX, g.choice=g.choice,m.choice=m.choice, pi.1=pi.1)
data$SNR  # the ratio of interactions("signal") vs. main effects("noise")
A <- data$A
y <- data$y
X <- data$X
Xm <- X
data$true.beta
data$true.eta
# generate test data
test.data <- generate.data2(n=n.test, p=p, correlationX=correlationX,sigmaX=sigmaX, g.choice=g.choice,m.choice=m.choice, pi.1=pi.1)
#test.data$y
xnew <- test.data$X
xmnew <- xnew   # main effect term
newA <- test.data$A
k = 4 + floor(n^{1/5.5})
head(xmnew)
setwd("~/Library/CloudStorage/OneDrive-NYULangoneHealth/Bayes_surfaceTBI/Bayesian-TBI")
mod <- cmdstan_model("./splinetbi.stan");
J = unique(A)
J
J = length(unique(A))
J
B <- splines::bs(X, df = 5, intercept = TRUE)
HEAD(b)
head(B)
summary(X)
summary(xnew)
N = nrow(X)
D =  ncol(X)
J = length(unique(A))
B <- splines::bs(X, df = 5, intercept = TRUE)
# matplot(dd$timeID, B, type = 'l', lty = 1,
#         xlab = "Time", ylab = "B-spline Basis",
#         main = "B-spline Basis Functions")
K_bspline <- 5 # Number of B-spline basis functions you desire (for example)
# Initialize a list to store B-spline matrices for each covariate
B_list <- vector("list", D)
for (d in 1:D) {
B_list[[d]] <- bs(X[, d], df = K_bspline, intercept = TRUE)
}
View(B_list)
B_list[[1]]
K_bspline = ncol(B)
studydata <- list(
N = N,
D = D,
X = X,
J = J,
K_bspline = K_bspline,
x,
Y = ..., # fill in appropriately
A = ..., # fill in appropriately
N_new = N_new,
Xnew = Xnew,
Bnew = array(unlist(Bnew_list), dim = c(N_new, K_bspline, D)),
Anew = ... # fill in appropriately)
studydata <- list(
N = N, D=D,
X=X, J=J,
y = y,
X=X,A=A, A_avg = mean(A))
fit_single <- single_mod$sample(
data = studydata,
refresh = 0,
chains = 4L,
parallel_chains = 4L,
iter_warmup = 500,
iter_sampling = 2500,
show_messages = FALSE)
# Check model divergence and get posterior distributions of parameters
diagnostics_df <- as_draws_df(fit_single$sampler_diagnostics())
div_single <- sum(diagnostics_df[, 'divergent__'])
# Get posterior draws of all parameters
draws_dt <- data.table(as_draws_df(fit_single$draws()))
#beta_0<- as.matrix(draws_dt[,c("beta_0")]) # estimation of treatment main effect
beta_1 <- as.matrix(draws_dt%>%select(paste0("beta","[",1:p,"]"))) #estimation of coefficients for treatment by covariate interaction
m <- as.matrix(draws_dt%>%select(paste0("m","[",1:p,"]"))) #estimation of covariates' main effects
#tau <- as.matrix(draws_dt[,c("tau")]) # intercept
return(data.table(beta_1,
m, div_single))
}
pred_sng_bayes <- function(xnew=NULL, xmnew=NULL, newA=NULL,A.mean=NULL, coefs = sgbayes.coefs,thresh = 0){
##Given patients characteristics, derive optimal treatment for each patients using simple Bayesian linear model
if(is.null(xnew))  xnew  <- bsim.obj$X
if(is.null(xmnew)) xmnew <- bsim.obj$Xm
if(is.null(newA))  newA  <- bsim.obj$A
n <- nrow(xnew)
p <- ncol(xnew)
# beta_0 <- as.matrix(coefs[,c("beta_0")])
beta_1 <- as.matrix(coefs%>%select(paste0("beta","[",1:p,"]")))
m <- as.matrix(coefs%>%select(paste0("m","[",1:p,"]"))) #estimation of covariates' main effects
#tau <- as.matrix(coefs[,c("tau")]) # int
nsample <-  nrow(beta_1)
eta.distr = contrast.distr = tbi.tmp  <- matrix(rep(0, n*nsample), n, nsample)
newA.mean <- newA-A.mean
for(i in 1:n){
eta.distr[i,] <- m%*%xnew[i,] + beta_1%*%xnew[i,]*newA.mean[i]#eta.distr (n.test*n.samples): a canonical parameter matrix with a row for each observation(test data point) and a column for each posterior sample
contrast.distr[i,] <- beta_1%*%xnew[i,]# samples of distribution of tbi (canonical parameter of A=2 - canonical parameter of A=1)
tbi.tmp[i,] <- (contrast.distr[i,] < thresh)#each row: ? tbi < 0 for the ith patient
}
tbi <- apply(tbi.tmp, 1, mean)#each row: Pr(tbi < 0) for the ith patient
return(list(eta.distr=eta.distr, contrast.distr =contrast.distr, tbi=tbi))
}
B = array(unlist(B_list), dim = c(N, K_bspline, D))
B
head(B)
head( B_list[[1]] )
summary(X)
summary(xnew)
attr(D, "knots")
attr(D, "Boundary.knots")
k
b.ini <- simml::simml(y, A, X, Xm, family=family, k=k, beta.ini=beta.ini)
beta.ini = betax  <- b.ini$beta.coef
x.beta <- X %*% betax
X <- as.matrix(X)
Xm <- as.matrix(Xm)
y <- as.vector(y)
A <- as.vector(A)
p <- ncol(X) #number of covariates for the interaction term
n <- nrow(X)
if(is.null(Xm)) Xm <- X
q <- ncol(Xm) #number of covariates for the main effects term
A <- as.numeric(as.factor(A))
A.unique <- unique(sort(A))
L <- length(A.unique)
A.mean <- mean(A)
Ac <<- A - A.mean
AXm <- cbind(1, A=Ac, Xm)
dat <- data.frame(y, A, X=X, Xm=Xm)
b.ini <- simml::simml(y, A, X, Xm, family=family, k=k, beta.ini=beta.ini)
beta.ini = betax  <- b.ini$beta.coef
x.beta <- X %*% betax
family = "binomial"
# initialize the parameters using a non-Bayesian single-index model (Park et al 2021 Biometrics)
b.ini <- simml::simml(y, A, X, Xm, family=family, k=k, beta.ini=beta.ini)
beta.ini = betax  <- b.ini$beta.coef
x.beta <- X %*% betax
head(x.beta)
d=1
knots[[d]] <- attr(B_list[[d]], "knots")   # specification of the knot location for the component function g.
knots <- list()
Boundary.knots <- list()
for (d in 1:D) {
B_list[[d]] <- splines::ns(X[, d], df = K_bspline)
knots[[d]] <- attr(B_list[[d]], "knots")   # specification of the knot location for the component function g.
Boundary.knots[[d]] <- attr(B_list[[d]], "Boundary.knots")
}
knots[[d]]
Boundary.knots[[d]]
N_new = nrow(xnew)
for (d in 1:D) {
Bnew_list[[d]] <- splines::ns(Xnew[, d], df = K_bspline, knots = knots[[d]], Boundary.knots = Boundary.knots[[d]])
}
Xnew =xnew
N_new = nrow(xnew)
for (d in 1:D) {
Bnew_list[[d]] <- splines::ns(xnew[, d], df = K_bspline, knots = knots[[d]], Boundary.knots = Boundary.knots[[d]])
}
Bnew_list <- vector("list", D)
N_new = nrow(xnew)
for (d in 1:D) {
Bnew_list[[d]] <- splines::ns(xnew[, d], df = K_bspline, knots = knots[[d]], Boundary.knots = Boundary.knots[[d]])
}
View(Bnew_list)
